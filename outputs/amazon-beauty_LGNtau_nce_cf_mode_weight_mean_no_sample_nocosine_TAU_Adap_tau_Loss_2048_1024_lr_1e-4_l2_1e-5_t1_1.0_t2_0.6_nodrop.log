2024-05-03 13:41:06,791 - [INFO] - {'dataset': 'amazon-beauty', 'data_path': './data/', 'name': 'amazon-beauty_LGNtau_nce_cf_mode_weight_mean_no_sample_nocosine_TAU_Adap_tau_Loss_2048_1024_lr_1e-4_l2_1e-5_t1_1.0_t2_0.6_nodrop_03_05_2024_13:41:06', 'train_ratio': 0.8, 'gnn': 'lgntaucf', 'epoch': 1000, 'batch_size': 2048, 'test_batch_size': 2048, 'dim': 64, 'l2': 1e-05, 'lr': 0.0001, 'mess_dropout': False, 'mess_dropout_rate': 0.1, 'edge_dropout': False, 'edge_dropout_rate': 0.1, 'n_negs': 1024, 'pool': 'mean', 'cuda': True, 'gpu_id': 0, 'Ks': '[5, 10, 15, 20, 25, 30, 40, 50]', 'context_hops': 3, 'eval_earlystop': 'recall@20', 'temperature': 1.0, 'temperature_2': 0.6, 'temperature_3': 1.0, 'u_norm': True, 'i_norm': True, 'out_dir': './weights/', 'log_dir': './log/', 'config_dir': './config/', 'restore': False, 'loss_fn': 'Adap_tau_Loss', 'sampling_method': 'no_sample', 'generate_mode': 'nocosine', 'tau_mode': 'weight_mean', 'cnt_lr': 100}
2024-05-03 13:41:07,156 - [INFO] - load train.txt
2024-05-03 13:41:08,293 - [INFO] - building the adj mat ...
2024-05-03 13:41:08,400 - [INFO] - train set len is 176139
2024-05-03 13:41:08,401 - [INFO] - test set len is 22363
2024-05-03 13:41:08,401 - [INFO] - loading over ...
2024-05-03 13:41:08,401 - [INFO] - users are 22363 items are 12101
Adap_tau_Loss
start to make tables
2024-05-03 13:41:17,834 - [INFO] - Evaluation Protocols is 1 @ 20
2024-05-03 13:41:17,834 - [INFO] - start training ...
6.435490250430879
2024-05-03 13:41:17,849 - [INFO] - current w_0 is 9.193557026776489
2024-05-03 13:41:23,258 - [INFO] - E:0|TAU:9.194 9.194, train_time: 4.885, VALID_time: 0.5236, loss: 548.1, emb_loss:9.451e-08, nce_loss:0.01415, best_valid(recall@20): -inf
valid 	 N@5: 0.00729, R@5: 0.01181, P@5: 0.002361
valid 	 N@10: 0.009583, R@10: 0.01892, P@10: 0.001892
valid 	 N@15: 0.01093, R@15: 0.02401, P@15: 0.001601
valid 	 N@20: 0.01187, R@20: 0.02799, P@20: 0.0014
valid 	 N@25: 0.01255, R@25: 0.03112, P@25: 0.001245
valid 	 N@30: 0.01299, R@30: 0.03327, P@30: 0.001109
valid 	 N@40: 0.01401, R@40: 0.03855, P@40: 0.0009636
valid 	 N@50: 0.01485, R@50: 0.0432, P@50: 0.0008639

6.435490250430879
2024-05-03 13:41:23,288 - [INFO] - current w_0 is 9.193557026776489
2024-05-03 13:41:28,677 - [INFO] - E:1|TAU:6.868 24.83, train_time: 4.874, VALID_time: 0.5147, loss: 490.7, emb_loss:1.027e-07, nce_loss:-0.005693, best_valid(recall@20): 0.02799
valid 	 N@5: 0.01087, R@5: 0.01735, P@5: 0.00347
valid 	 N@10: 0.01392, R@10: 0.02687, P@10: 0.002687
valid 	 N@15: 0.01558, R@15: 0.03318, P@15: 0.002212
valid 	 N@20: 0.01695, R@20: 0.03899, P@20: 0.00195
valid 	 N@25: 0.01802, R@25: 0.04387, P@25: 0.001755
valid 	 N@30: 0.01899, R@30: 0.04861, P@30: 0.00162
valid 	 N@40: 0.0203, R@40: 0.05536, P@40: 0.001384
valid 	 N@50: 0.02144, R@50: 0.06171, P@50: 0.001234

6.435490250430879
2024-05-03 13:41:28,711 - [INFO] - current w_0 is 9.193557026776489
2024-05-03 13:41:34,083 - [INFO] - E:2|TAU:6.774 24.83, train_time: 4.866, VALID_time: 0.5048, loss: 471.1, emb_loss:1.078e-07, nce_loss:-0.02938, best_valid(recall@20): 0.03899
valid 	 N@5: 0.01119, R@5: 0.01771, P@5: 0.003542
valid 	 N@10: 0.01437, R@10: 0.02763, P@10: 0.002763
valid 	 N@15: 0.01637, R@15: 0.03515, P@15: 0.002343
valid 	 N@20: 0.01791, R@20: 0.04168, P@20: 0.002084
valid 	 N@25: 0.0191, R@25: 0.04713, P@25: 0.001885
valid 	 N@30: 0.02022, R@30: 0.05259, P@30: 0.001753
valid 	 N@40: 0.02189, R@40: 0.06122, P@40: 0.00153
valid 	 N@50: 0.02321, R@50: 0.06855, P@50: 0.001371

6.435490250430879
2024-05-03 13:41:34,124 - [INFO] - current w_0 is 9.193557026776489
2024-05-03 13:41:39,495 - [INFO] - E:3|TAU:6.743 24.84, train_time: 4.866, VALID_time: 0.5041, loss: 426.5, emb_loss:1.129e-07, nce_loss:-0.04503, best_valid(recall@20): 0.04168
valid 	 N@5: 0.01443, R@5: 0.02231, P@5: 0.004463
valid 	 N@10: 0.01891, R@10: 0.03622, P@10: 0.003622
valid 	 N@15: 0.0219, R@15: 0.04749, P@15: 0.003166
valid 	 N@20: 0.02397, R@20: 0.0563, P@20: 0.002815
valid 	 N@25: 0.02552, R@25: 0.06341, P@25: 0.002536
valid 	 N@30: 0.02693, R@30: 0.07025, P@30: 0.002342
valid 	 N@40: 0.02889, R@40: 0.08036, P@40: 0.002009
valid 	 N@50: 0.03056, R@50: 0.08957, P@50: 0.001791

6.435490250430879
2024-05-03 13:41:39,542 - [INFO] - current w_0 is 9.193557026776489
2024-05-03 13:41:44,943 - [INFO] - E:4|TAU:6.722 24.83, train_time: 4.871, VALID_time: 0.5284, loss: 399.6, emb_loss:1.189e-07, nce_loss:-0.04472, best_valid(recall@20): 0.0563
valid 	 N@5: 0.0161, R@5: 0.02526, P@5: 0.005053
valid 	 N@10: 0.02138, R@10: 0.04168, P@10: 0.004168
valid 	 N@15: 0.02451, R@15: 0.05353, P@15: 0.003568
valid 	 N@20: 0.02687, R@20: 0.06354, P@20: 0.003177
valid 	 N@25: 0.02846, R@25: 0.07083, P@25: 0.002833
valid 	 N@30: 0.02976, R@30: 0.07714, P@30: 0.002571
valid 	 N@40: 0.03194, R@40: 0.0884, P@40: 0.00221
valid 	 N@50: 0.03375, R@50: 0.09842, P@50: 0.001968

6.435490250430879
2024-05-03 13:41:44,985 - [INFO] - current w_0 is 9.193557026776489
2024-05-03 13:41:50,355 - [INFO] - E:5|TAU:6.652 24.83, train_time: 4.865, VALID_time: 0.5049, loss: 384.9, emb_loss:1.238e-07, nce_loss:-0.0527, best_valid(recall@20): 0.06354
valid 	 N@5: 0.01662, R@5: 0.02598, P@5: 0.005196
valid 	 N@10: 0.02185, R@10: 0.04221, P@10: 0.004221
valid 	 N@15: 0.02486, R@15: 0.05362, P@15: 0.003574
valid 	 N@20: 0.02711, R@20: 0.06314, P@20: 0.003157
valid 	 N@25: 0.02874, R@25: 0.07061, P@25: 0.002824
valid 	 N@30: 0.03023, R@30: 0.07781, P@30: 0.002594
valid 	 N@40: 0.03258, R@40: 0.08997, P@40: 0.002249
valid 	 N@50: 0.03461, R@50: 0.1012, P@50: 0.002024

6.435490250430879
2024-05-03 13:41:50,363 - [INFO] - current w_0 is 9.193557026776489
